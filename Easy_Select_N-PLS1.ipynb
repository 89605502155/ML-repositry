{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools as it\n",
    "import  subprocess\n",
    "import sys\n",
    "import os\n",
    "from N_PLS1_help_scripts.EasySelectWaveLenth import firstSellectionVariables as sell\n",
    "import numpy as np\n",
    "from gzip import open # NB: overrides standard open()\n",
    "import pickle as pkl\n",
    "#import tensorly as tl\n",
    "#from tensorly.base import tensor_to_vec,  partial_tensor_to_vec\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib as mpl\n",
    "from glob import glob\n",
    "import math\n",
    "import functools\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "import sklearn\n",
    "from N_PLS1_help_scripts.CenteringClass import centrir\n",
    "from N_PLS1_help_scripts.Crosswal_With_Out_Centering import crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdata_numpy = pkl.load(open('C:/Users/admin/Desktop/PLS2021/N-PLS/X_new.pkl.gz', 'rb'))\n",
    "Ydata = pkl.load(open('C:/Users/admin/Desktop/PLS2021/N-PLS/y.pkl.gz', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=list(it.product([i for i in range(2,5)],[i for i in range(2,11)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tri_PLS1_grid(RegressorMixin,BaseEstimator):\n",
    "    def  __init__(self, n_components=2,a=3):\n",
    "        self.n_components = n_components\n",
    "        self.a=a\n",
    "        \n",
    "            \n",
    "    def fit(self, xx, yy):\n",
    "        \"\"\"Fits the model to the data (X, y)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray\n",
    "        y : 1D-array of shape (n_samples, )\n",
    "            labels associated with each sample\"\"\"\n",
    "        x=xx.copy()\n",
    "        y=yy.copy()        \n",
    "        Tt=np.zeros([x.shape[0],self.n_components])\n",
    "        mass=np.zeros([y.shape[0]])\n",
    "        y_copy=yy.copy()\n",
    "        \"\"\"\"\n",
    "        При различных способах разрезания исходных данных, массивы w_k и w_i имеют похожие значения и именно их я планирую \n",
    "        использовать для функции predict данного класса. \"\"\"\n",
    "        w_k_mass=np.zeros([self.n_components,x.shape[1],1])\n",
    "        w_i_mass=np.zeros([self.n_components,x.shape[2],1])\n",
    "        bf_array=[]\n",
    "        \n",
    "        mmas=np.zeros([x.shape[0],x.shape[1],x.shape[2]])\n",
    "        z_pz=np.eye(x.shape[1])\n",
    "        z_z=z_pz[:,:x.shape[2]]\n",
    "        \n",
    "        for f in range(0,self.n_components):\n",
    "            z=np.zeros([x.shape[1],x.shape[2]])\n",
    "            x_product=np.zeros([x.shape[0],x.shape[1],x.shape[2]])\n",
    "            \n",
    "            for i in range(0,x.shape[0]):\n",
    "                x_product[i,:,:]=y[i]*x[i,:,:]\n",
    "            z=x_product.sum(axis=0)\n",
    "            \n",
    "            # Блок регуляризации z\n",
    "            #z_po=LA.pinv(z)\n",
    "            #z=np.dot((np.dot(z,z_po)+(self.a*np.eye(z.shape[0]))),z)\n",
    "            \n",
    "            \n",
    "            Wk, S, WI = np.linalg.svd(z)\n",
    "            #plt.imshow(Wk, aspect='auto')\n",
    "            #plt.imshow(WI, aspect='auto')\n",
    "            #plt.imshow(S, aspect='auto')\n",
    "            #plt.show();\n",
    "            w_k=np.array(Wk[:,0]).reshape(x.shape[1],1)\n",
    "            w_i=np.array(WI[0,:]).reshape(x.shape[2],1)\n",
    "            w_k_mass[f,:,:]=w_k\n",
    "            w_i_mass[f,:,:]=w_i\n",
    "            \n",
    "            for h in range(0,x.shape[0]):\n",
    "                 Tt[h,f]=np.dot(np.dot(w_i.transpose(),x[h,:,:].transpose()),w_k)\n",
    "            T=np.array(Tt[:,0:f+1]).reshape(x.shape[0],f+1)        \n",
    "            #print(T)\n",
    "            #print((np.dot(np.linalg.inv(np.dot(T,T.transpose())+(self.a*np.eye(x.shape[0]))),T)).shape)\n",
    "            \n",
    "            \n",
    "            \n",
    "            bf=np.dot((np.dot(np.linalg.inv(np.dot(T,T.transpose())-(((self.a/(10*f+1)))*np.eye(x.shape[0]))),T)).transpose(),\n",
    "                          y.reshape([x.shape[0],1]))\n",
    "            #print(bf.shape) (self.a/(f+1)\n",
    "            #print((np.dot(T,bf)).shape).reshape(x.shape[1],x.shape[2])\n",
    "            bf_array+=[bf]\n",
    "            #plt.plot(bf)\n",
    "            #plt.show();\n",
    "            \n",
    "            WW=np.kron(w_k,w_i).reshape(x.shape[1],x.shape[2])\n",
    "            for g in range(0,x.shape[0]):\n",
    "                mmas[g,:,:]=Tt[g,f]*WW\n",
    "            #mmas=np.kron(Tt[:,f],WW).reshape(x.shape[0],x.shape[1],x.shape[2])\n",
    "            x=np.array(x-(mmas)) \n",
    "            #plt.imshow(mmas[5,:,:], aspect='auto')\n",
    "            #plt.show();\n",
    "            #for g in range(0,x.shape[0]):\n",
    "            \n",
    "            #plt.imshow(np.kron(w_k,w_i).reshape(x.shape[1],x.shape[2]), aspect='auto')\n",
    "            #plt.show();\n",
    "            \n",
    "            Y_m=(np.dot(T,bf)).reshape(x.shape[0])\n",
    "            #plt.plot(Y_m, color=\"red\")\n",
    "            #plt.plot(y_copy, color=\"blue\")\n",
    "            \n",
    "            y=(y-(np.dot(T,bf)).reshape(x.shape[0]))\n",
    "            \n",
    "            #plt.plot(y, color=\"green\")\n",
    "    \n",
    "            #print(y)\n",
    "            mass+=(np.dot(T,bf)).reshape(x.shape[0]).reshape(x.shape[0])\n",
    "            #plt.plot(mass, color=\"yellow\")\n",
    "            #plt.show();\n",
    "            bf=0\n",
    "            \n",
    "        self.bf_array=bf_array\n",
    "        self.train_error=mean_squared_error(mass,y_copy)\n",
    "        self.w_k=w_k_mass\n",
    "        self.w_i=w_i_mass\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    #def fit_transform(self,x.copy()):\n",
    "        \"\"\"\"\n",
    "        Даже для 20 компонент функция fit работает быстро, а вот функция predict нет.\n",
    "        Кроме того, некоторые вычислительные операции требуют колоссальных \n",
    "        объёмов памяти, поэтому, сначала нужно провести анализ нагрузок и \n",
    "        трансформацию данных в форму поменьше.\n",
    "        \n",
    "        Отбор длин волн я решил делать при помощи поглощающих жадных алгоритмов поиска. SBS алгоритм.\n",
    "        \"\"\"\n",
    "    \n",
    "    def predict(self, xx):\n",
    "        x=xx.copy()\n",
    "        Tt=np.zeros([x.shape[0],self.n_components])\n",
    "        #y=np.random.normal(loc=0,scale=10,size=x.shape[0])\n",
    "        y=np.zeros([x.shape[0]])\n",
    "        mmas=np.zeros([x.shape[0],x.shape[1],x.shape[2]])\n",
    "        for f in range(0,self.n_components):\n",
    "            w_k=self.w_k[f,:,:]\n",
    "            w_i=self.w_i[f,:,:]\n",
    "            for h in range(0,x.shape[0]):\n",
    "                 Tt[h,f]=np.dot(np.dot(w_i.transpose(),x[h,:,:].transpose()),w_k)\n",
    "            \n",
    "            T=np.array(Tt[:,0:f+1]).reshape(x.shape[0],f+1)\n",
    "            #bf=np.dot((np.dot(np.linalg.inv(np.dot(T,T.transpose())),T)).transpose(),\n",
    "            #              y.reshape([x.shape[0],1]))\n",
    "            WW=np.kron(w_k,w_i).reshape(x.shape[1],x.shape[2])\n",
    "            #plt.imshow(WW, aspect='auto')\n",
    "            #plt.show();\n",
    "            for g in range(0,x.shape[0]):\n",
    "                #mmas[g,:,:]=Tt[g,f]*WW\n",
    "                mmas[g,:,:]=Tt[g,f]*WW\n",
    "            x=np.array(x-(mmas))\n",
    "            #print(len(np.kron(Tt[:,f],np.kron(w_i,w_k).reshape(x.shape[1],x.shape[2]))))\n",
    "            #print()\n",
    "            #plt.plot(self.bf_array[f])\n",
    "            #plt.show();\n",
    "            \n",
    "            #bf=np.dot((np.dot(np.linalg.inv(np.dot(T,T.transpose())-(self.a*np.eye(x.shape[0]))),T)).transpose(),\n",
    "             #             y.reshape([x.shape[0],1]))\n",
    "            \n",
    "            y=(y+(np.dot(T,self.bf_array[f])).reshape(x.shape[0]))\n",
    "            #y=(y+(np.dot(T,bf)).reshape(x.shape[0]))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_r2_cv=dict()\n",
    "er_r2_c=dict()\n",
    "er_r2_p=dict()\n",
    "er_mse_cv=dict()\n",
    "er_mse_cv_otn=dict()\n",
    "er_mse_c=dict()\n",
    "#er_mse_cv=dict()\n",
    "er_new_excitation=dict()\n",
    "er_new_emission=dict()\n",
    "er_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
